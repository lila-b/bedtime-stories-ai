{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Story Generator - Winnie the Pooh \n",
    "\n",
    "## Part 1: Processsing Texts and Vector Database\n",
    "\n",
    "[1. Imports and environment](#1-imports-and-environment)\n",
    "\n",
    "[2. Inspect text](#2-inspect-text)\n",
    "\n",
    "[3. Load and chunk data](#3-load-and-chunk-data)\n",
    "\n",
    "[4. Chroma database](#4-chroma-database)\n",
    "\n",
    "[5. Execute](#5-execute)\n",
    "\n",
    "[6. Querying database](#6-querying-database)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Imports and environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting langchain\n",
      "  Using cached langchain-0.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain-community\n",
      "  Using cached langchain_community-0.3.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting langchain-openai\n",
      "  Using cached langchain_openai-0.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting chromadb\n",
      "  Using cached chromadb-0.5.5-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting chromadbx\n",
      "  Using cached chromadbx-0.0.5-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.2.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/Lila/Desktop/SpringBoard/Github/bedtime-stories-ai/.venv/lib/python3.11/site-packages (from langchain) (6.0.2)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.35-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Using cached aiohttp-3.10.5-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.5 kB)\n",
      "Collecting langchain-core<0.4.0,>=0.3.0 (from langchain)\n",
      "  Using cached langchain_core-0.3.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Using cached langsmith-0.1.121-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy<2,>=1 (from langchain)\n",
      "  Using cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (114 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Using cached pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/Lila/Desktop/SpringBoard/Github/bedtime-stories-ai/.venv/lib/python3.11/site-packages (from langchain) (2.32.3)\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain)\n",
      "  Using cached tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Using cached pydantic_settings-2.5.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting openai<2.0.0,>=1.40.0 (from langchain-openai)\n",
      "  Using cached openai-1.46.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
      "  Using cached tiktoken-0.7.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Using cached build-1.2.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
      "  Using cached chroma_hnswlib-0.7.6-cp311-cp311-macosx_11_0_arm64.whl.metadata (252 bytes)\n",
      "Collecting fastapi>=0.95.2 (from chromadb)\n",
      "  Using cached fastapi-0.115.0-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached uvicorn-0.30.6-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting posthog>=2.4.0 (from chromadb)\n",
      "  Using cached posthog-3.6.6-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/Lila/Desktop/SpringBoard/Github/bedtime-stories-ai/.venv/lib/python3.11/site-packages (from chromadb) (4.12.2)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Using cached onnxruntime-1.19.2-cp311-cp311-macosx_11_0_universal2.whl.metadata (4.5 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_api-1.27.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Using cached opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_sdk-1.27.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting tokenizers>=0.13.2 (from chromadb)\n",
      "  Using cached tokenizers-0.20.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Using cached PyPika-0.48.9-py2.py3-none-any.whl\n",
      "Collecting tqdm>=4.65.0 (from chromadb)\n",
      "  Using cached tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /Users/Lila/Desktop/SpringBoard/Github/bedtime-stories-ai/.venv/lib/python3.11/site-packages (from chromadb) (7.7.0)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Using cached importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb)\n",
      "  Using cached grpcio-1.66.1-cp311-cp311-macosx_10_9_universal2.whl.metadata (3.9 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Using cached bcrypt-4.2.0-cp39-abi3-macosx_10_12_universal2.whl.metadata (9.6 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb)\n",
      "  Using cached typer-0.12.5-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Using cached kubernetes-30.1.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Using cached mmh3-4.1.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting orjson>=3.9.12 (from chromadb)\n",
      "  Using cached orjson-3.10.7-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (50 kB)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /Users/Lila/Desktop/SpringBoard/Github/bedtime-stories-ai/.venv/lib/python3.11/site-packages (from chromadb) (0.27.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/Lila/Desktop/SpringBoard/Github/bedtime-stories-ai/.venv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiohappyeyeballs-2.4.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/Lila/Desktop/SpringBoard/Github/bedtime-stories-ai/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached frozenlist-1.4.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached multidict-6.1.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.0 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached yarl-1.11.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: packaging>=19.1 in /Users/Lila/Desktop/SpringBoard/Github/bedtime-stories-ai/.venv/lib/python3.11/site-packages (from build>=1.0.3->chromadb) (24.1)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Using cached pyproject_hooks-1.1.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting starlette<0.39.0,>=0.37.2 (from fastapi>=0.95.2->chromadb)\n",
      "  Using cached starlette-0.38.5-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: anyio in /Users/Lila/Desktop/SpringBoard/Github/bedtime-stories-ai/.venv/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb) (4.4.0)\n",
      "Requirement already satisfied: certifi in /Users/Lila/Desktop/SpringBoard/Github/bedtime-stories-ai/.venv/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/Lila/Desktop/SpringBoard/Github/bedtime-stories-ai/.venv/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb) (1.0.5)\n",
      "Requirement already satisfied: idna in /Users/Lila/Desktop/SpringBoard/Github/bedtime-stories-ai/.venv/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
      "Requirement already satisfied: sniffio in /Users/Lila/Desktop/SpringBoard/Github/bedtime-stories-ai/.venv/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/Lila/Desktop/SpringBoard/Github/bedtime-stories-ai/.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/Lila/Desktop/SpringBoard/Github/bedtime-stories-ai/.venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached google_auth-2.34.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /Users/Lila/Desktop/SpringBoard/Github/bedtime-stories-ai/.venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /Users/Lila/Desktop/SpringBoard/Github/bedtime-stories-ai/.venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.0->langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached protobuf-5.28.1-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
      "Collecting sympy (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached sympy-1.13.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.40.0->langchain-openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.40.0->langchain-openai)\n",
      "  Using cached jiter-0.5.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.6 kB)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting importlib-metadata<=8.4.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Using cached importlib_metadata-8.4.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached googleapis_common_protos-1.65.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.27.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.27.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_proto-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached protobuf-4.25.4-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation-0.48b0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-util-http==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_util_http-0.48b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: setuptools>=16.0 in /Users/Lila/Desktop/SpringBoard/Github/bedtime-stories-ai/.venv/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (65.5.0)\n",
      "Collecting wrapt<2.0.0,>=1.0.0 (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached wrapt-1.16.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
      "  Using cached monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading pydantic_core-2.23.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/Lila/Desktop/SpringBoard/Github/bedtime-stories-ai/.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain-openai)\n",
      "  Using cached regex-2024.9.11-cp311-cp311-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from tokenizers>=0.13.2->chromadb)\n",
      "  Using cached huggingface_hub-0.25.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting click>=8.0.0 (from typer>=0.9.0->chromadb)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer>=0.9.0->chromadb)\n",
      "  Using cached rich-13.8.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached httptools-0.6.1-cp311-cp311-macosx_10_9_universal2.whl.metadata (3.6 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached uvloop-0.20.0-cp311-cp311-macosx_10_9_universal2.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached watchfiles-0.24.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached websockets-13.0.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting filelock (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb)\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb)\n",
      "  Using cached fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting zipp>=0.5 (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api>=1.2.0->chromadb)\n",
      "  Using cached zipp-3.20.2-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/Lila/Desktop/SpringBoard/Github/bedtime-stories-ai/.venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain) (3.0.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer>=0.9.0->chromadb)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/Lila/Desktop/SpringBoard/Github/bedtime-stories-ai/.venv/lib/python3.11/site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (2.18.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Using cached langchain-0.3.0-py3-none-any.whl (1.0 MB)\n",
      "Using cached langchain_community-0.3.0-py3-none-any.whl (2.3 MB)\n",
      "Using cached langchain_openai-0.2.0-py3-none-any.whl (51 kB)\n",
      "Using cached chromadb-0.5.5-py3-none-any.whl (584 kB)\n",
      "Using cached chroma_hnswlib-0.7.6-cp311-cp311-macosx_11_0_arm64.whl (185 kB)\n",
      "Using cached chromadbx-0.0.5-py3-none-any.whl (9.6 kB)\n",
      "Using cached pandas-2.2.2-cp311-cp311-macosx_11_0_arm64.whl (11.3 MB)\n",
      "Using cached aiohttp-3.10.5-cp311-cp311-macosx_11_0_arm64.whl (388 kB)\n",
      "Using cached bcrypt-4.2.0-cp39-abi3-macosx_10_12_universal2.whl (472 kB)\n",
      "Using cached build-1.2.2-py3-none-any.whl (22 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached fastapi-0.115.0-py3-none-any.whl (94 kB)\n",
      "Using cached grpcio-1.66.1-cp311-cp311-macosx_10_9_universal2.whl (10.6 MB)\n",
      "Using cached kubernetes-30.1.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Using cached langchain_core-0.3.1-py3-none-any.whl (405 kB)\n",
      "Using cached langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n",
      "Using cached langsmith-0.1.121-py3-none-any.whl (289 kB)\n",
      "Using cached mmh3-4.1.0-cp311-cp311-macosx_11_0_arm64.whl (30 kB)\n",
      "Using cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)\n",
      "Using cached onnxruntime-1.19.2-cp311-cp311-macosx_11_0_universal2.whl (16.8 MB)\n",
      "Using cached openai-1.46.0-py3-none-any.whl (375 kB)\n",
      "Using cached opentelemetry_api-1.27.0-py3-none-any.whl (63 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl (18 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl (17 kB)\n",
      "Using cached opentelemetry_proto-1.27.0-py3-none-any.whl (52 kB)\n",
      "Using cached opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl (11 kB)\n",
      "Using cached opentelemetry_instrumentation-0.48b0-py3-none-any.whl (29 kB)\n",
      "Using cached opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl (15 kB)\n",
      "Using cached opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl (149 kB)\n",
      "Using cached opentelemetry_util_http-0.48b0-py3-none-any.whl (6.9 kB)\n",
      "Using cached opentelemetry_sdk-1.27.0-py3-none-any.whl (110 kB)\n",
      "Using cached orjson-3.10.7-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (251 kB)\n",
      "Using cached posthog-3.6.6-py2.py3-none-any.whl (54 kB)\n",
      "Using cached pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "Downloading pydantic_core-2.23.4-cp311-cp311-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pydantic_settings-2.5.2-py3-none-any.whl (26 kB)\n",
      "Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Downloading SQLAlchemy-2.0.35-cp311-cp311-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Using cached tiktoken-0.7.0-cp311-cp311-macosx_11_0_arm64.whl (907 kB)\n",
      "Using cached tokenizers-0.20.0-cp311-cp311-macosx_11_0_arm64.whl (2.5 MB)\n",
      "Using cached tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "Using cached typer-0.12.5-py3-none-any.whl (47 kB)\n",
      "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Using cached uvicorn-0.30.6-py3-none-any.whl (62 kB)\n",
      "Using cached importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
      "Using cached aiohappyeyeballs-2.4.0-py3-none-any.whl (12 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached frozenlist-1.4.1-cp311-cp311-macosx_11_0_arm64.whl (53 kB)\n",
      "Using cached google_auth-2.34.0-py2.py3-none-any.whl (200 kB)\n",
      "Using cached googleapis_common_protos-1.65.0-py2.py3-none-any.whl (220 kB)\n",
      "Using cached httptools-0.6.1-cp311-cp311-macosx_10_9_universal2.whl (145 kB)\n",
      "Using cached huggingface_hub-0.25.0-py3-none-any.whl (436 kB)\n",
      "Using cached importlib_metadata-8.4.0-py3-none-any.whl (26 kB)\n",
      "Using cached jiter-0.5.0-cp311-cp311-macosx_11_0_arm64.whl (299 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
      "Using cached monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Using cached multidict-6.1.0-cp311-cp311-macosx_11_0_arm64.whl (29 kB)\n",
      "Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Using cached protobuf-4.25.4-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "Using cached regex-2024.9.11-cp311-cp311-macosx_11_0_arm64.whl (284 kB)\n",
      "Using cached rich-13.8.1-py3-none-any.whl (241 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached starlette-0.38.5-py3-none-any.whl (71 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached uvloop-0.20.0-cp311-cp311-macosx_10_9_universal2.whl (1.3 MB)\n",
      "Using cached watchfiles-0.24.0-cp311-cp311-macosx_11_0_arm64.whl (367 kB)\n",
      "Using cached websockets-13.0.1-cp311-cp311-macosx_11_0_arm64.whl (148 kB)\n",
      "Using cached yarl-1.11.1-cp311-cp311-macosx_11_0_arm64.whl (112 kB)\n",
      "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Using cached pyproject_hooks-1.1.0-py3-none-any.whl (9.2 kB)\n",
      "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Using cached sympy-1.13.2-py3-none-any.whl (6.2 MB)\n",
      "Using cached asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Using cached cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Using cached fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Using cached pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Using cached wrapt-1.16.0-cp311-cp311-macosx_11_0_arm64.whl (38 kB)\n",
      "Using cached zipp-3.20.2-py3-none-any.whl (9.2 kB)\n",
      "Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: pytz, pypika, mpmath, monotonic, mmh3, flatbuffers, zipp, wrapt, websockets, uvloop, tzdata, tqdm, tenacity, sympy, SQLAlchemy, shellingham, regex, python-dotenv, pyproject_hooks, pydantic-core, pyasn1, protobuf, orjson, opentelemetry-util-http, oauthlib, numpy, mypy-extensions, multidict, mdurl, marshmallow, jsonpatch, jiter, importlib-resources, humanfriendly, httptools, grpcio, fsspec, frozenlist, filelock, distro, click, cachetools, bcrypt, backoff, asgiref, annotated-types, aiohappyeyeballs, yarl, watchfiles, uvicorn, typing-inspect, tiktoken, starlette, rsa, requests-oauthlib, pydantic, pyasn1-modules, posthog, pandas, opentelemetry-proto, markdown-it-py, importlib-metadata, huggingface-hub, googleapis-common-protos, deprecated, coloredlogs, chroma-hnswlib, build, aiosignal, tokenizers, rich, pydantic-settings, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, openai, onnxruntime, langsmith, google-auth, fastapi, dataclasses-json, aiohttp, typer, opentelemetry-semantic-conventions, opentelemetry-instrumentation, langchain-core, kubernetes, opentelemetry-sdk, opentelemetry-instrumentation-asgi, langchain-text-splitters, langchain-openai, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, langchain, langchain-community, chromadb, chromadbx\n",
      "Successfully installed SQLAlchemy-2.0.35 aiohappyeyeballs-2.4.0 aiohttp-3.10.5 aiosignal-1.3.1 annotated-types-0.7.0 asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.0 build-1.2.2 cachetools-5.5.0 chroma-hnswlib-0.7.6 chromadb-0.5.5 chromadbx-0.0.5 click-8.1.7 coloredlogs-15.0.1 dataclasses-json-0.6.7 deprecated-1.2.14 distro-1.9.0 fastapi-0.115.0 filelock-3.16.1 flatbuffers-24.3.25 frozenlist-1.4.1 fsspec-2024.9.0 google-auth-2.34.0 googleapis-common-protos-1.65.0 grpcio-1.66.1 httptools-0.6.1 huggingface-hub-0.25.0 humanfriendly-10.0 importlib-metadata-8.4.0 importlib-resources-6.4.5 jiter-0.5.0 jsonpatch-1.33 kubernetes-30.1.0 langchain-0.3.0 langchain-community-0.3.0 langchain-core-0.3.1 langchain-openai-0.2.0 langchain-text-splitters-0.3.0 langsmith-0.1.121 markdown-it-py-3.0.0 marshmallow-3.22.0 mdurl-0.1.2 mmh3-4.1.0 monotonic-1.6 mpmath-1.3.0 multidict-6.1.0 mypy-extensions-1.0.0 numpy-1.26.4 oauthlib-3.2.2 onnxruntime-1.19.2 openai-1.46.0 opentelemetry-api-1.27.0 opentelemetry-exporter-otlp-proto-common-1.27.0 opentelemetry-exporter-otlp-proto-grpc-1.27.0 opentelemetry-instrumentation-0.48b0 opentelemetry-instrumentation-asgi-0.48b0 opentelemetry-instrumentation-fastapi-0.48b0 opentelemetry-proto-1.27.0 opentelemetry-sdk-1.27.0 opentelemetry-semantic-conventions-0.48b0 opentelemetry-util-http-0.48b0 orjson-3.10.7 pandas-2.2.2 posthog-3.6.6 protobuf-4.25.4 pyasn1-0.6.1 pyasn1-modules-0.4.1 pydantic-2.9.2 pydantic-core-2.23.4 pydantic-settings-2.5.2 pypika-0.48.9 pyproject_hooks-1.1.0 python-dotenv-1.0.1 pytz-2024.2 regex-2024.9.11 requests-oauthlib-2.0.0 rich-13.8.1 rsa-4.9 shellingham-1.5.4 starlette-0.38.5 sympy-1.13.2 tenacity-8.5.0 tiktoken-0.7.0 tokenizers-0.20.0 tqdm-4.66.5 typer-0.12.5 typing-inspect-0.9.0 tzdata-2024.1 uvicorn-0.30.6 uvloop-0.20.0 watchfiles-0.24.0 websockets-13.0.1 wrapt-1.16.0 yarl-1.11.1 zipp-3.20.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install python-dotenv langchain langchain-community langchain-openai chromadb chromadbx pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import shutil \n",
    "from dotenv import load_dotenv \n",
    "import re \n",
    "import pandas as pd\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter # for chunking text \n",
    "import chromadb \n",
    "from chromadb.utils import embedding_functions # ChromaDB embedding functions\n",
    "from chromadbx import UUIDGenerator # for generating UUIDs \n",
    "\n",
    "default_ef = embedding_functions.DefaultEmbeddingFunction()\n",
    "\n",
    "# Set up OpenAI API key\n",
    "load_dotenv()\n",
    "#openai_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# File paths\n",
    "DATA_PATH = \"../data/raw\"\n",
    "CHROMA_PATH = \"../data/chroma_db\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Inspect text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters: 79 \n",
      "\n",
      "Non-alphanumeric characters: \n",
      "{' ': 23567, '-': 682, '\\n': 3612, '_': 582, '.': 1692, '\"': 2417, \"'\": 689, '&': 2, ',': 2187, '?': 342, '(': 27, ')': 27, '!': 252, ';': 55, '*': 38, ':': 43} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(DATA_PATH, \"winnie_the_pooh.txt\"), 'r', encoding='utf-8') as file:\n",
    "    full_text = file.read()\n",
    "\n",
    "char_count = {}\n",
    "\n",
    "# Count the number of times each character appears in the text\n",
    "for char in full_text:\n",
    "    if char in char_count:\n",
    "        char_count[char] += 1\n",
    "    else:\n",
    "        char_count[char] = 1\n",
    "\n",
    "print(f\"Number of unique characters: {len(char_count.keys())} \\n\")\n",
    "\n",
    "# Filter only non-alphanumeric characters\n",
    "filtered_char_count = {char: count for char, count in char_count.items() if not char.isalnum()}\n",
    "print(\"Non-alphanumeric characters: \")\n",
    "print(filtered_char_count, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    _BY A. A. MILNE_\n",
      "                    _JUVENILES_\n",
      "    \"_The best book of ver\n",
      "ses for children_ _ever written._\"--A. \n",
      "    NEWTON in _The Atlantic Monthly\n",
      "_.\n",
      "                    _ESSAYS_\n",
      "                    _MYSTERY STORY_\n",
      " voice, \"What about _Me_?\" \"My dear Pigle\n",
      "saying, \"What about _Us_?\" So perhaps the\n",
      "on't you know what '_ther_' means?\"\n",
      "\"_What_ about a story?\" I s\n",
      "mself. Because he's _that_ sort of Bear.\"\n",
      "(_\"What does 'under th\n",
      "d Christopher Robin._\n",
      "\"_It means he had the \n",
      "under it._\"\n",
      "_\"Winnie-the-Pooh was\n",
      "d Christopher Robin._\n",
      "_\"Now I am,\" said a g\n",
      "                 *        *        *        *        *\n",
      "                 *        *        *        *        *\n",
      "                 *        *        *        *        *\n",
      "BANG!!!???***!!!\n",
      "                 *        *        *        *        *\n",
      "                 *        *        *        *        *\n",
      "                 *        *        *        *        *\n",
      "                 *        *        *        *        *\n"
     ]
    }
   ],
   "source": [
    "# find instances of underscores in the text to see how they are used \n",
    "matches_1 = re.findall(r'.{0,20}\\_.{0,20}', full_text)\n",
    "for match in matches_1[:20]:\n",
    "    print(match)\n",
    "\n",
    "matches_2 = re.findall(r'.{0,30}\\*.{0,30}', full_text)\n",
    "for match in matches_2:\n",
    "    print(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Underscores and asterisks are not typical punctuations, so I want to check how they are being used in the text. Based on the results below, they both appear to be superfluous, and will be premoved in the processing/chunking steps. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load and chunk data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_documents(filepath, filename=\"winnie_the_pooh.txt\"):\n",
    "  \"\"\"\n",
    "  Load TXT documents from the specified directory. \n",
    "  Remove whitespace and split into individual stories by chapter.\n",
    "  Filename defaults to winnie_the_pooh.txt, but can be specified for other files. \n",
    "\n",
    "  Returns:\n",
    "    List of chapters, removing first title pages.\n",
    "  \"\"\"\n",
    "\n",
    "  with open(os.path.join(filepath, filename), 'r', encoding='utf-8') as file:\n",
    "    story = file.read()\n",
    "\n",
    "    # remove whitespace and underscores \n",
    "    story = re.sub(r'\\s+', ' ', story)\n",
    "    story = re.sub(r\"_\", \"\", story)\n",
    "    story = re.sub(r\"\\*\", \"\", story)\n",
    "\n",
    "    #split into individual stories by chapter\n",
    "    stories_list = story.split(\"CHAPTER \")\n",
    "    \n",
    "    return stories_list[1:] # first element is title pages. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stories: 10 \n",
      "\n",
      "Length of first story: 11613 \n",
      "\n",
      "Preview of first story: \n",
      "I IN WHICH WE ARE INTRODUCED TO WINNIE-THE-POOH AND SOME BEES, AND THE STORIES BEGIN Here is Edward Bear, coming downstairs now, bump, bump, bump, on  ...\n"
     ]
    }
   ],
   "source": [
    "documents = load_documents(DATA_PATH) \n",
    "\n",
    "# Check results are as expected\n",
    "print(f\"Number of stories: {len(documents)} \\n\")\n",
    "print(f\"Length of first story: {len(documents[0])} \\n\")\n",
    "print(\"Preview of first story: \")\n",
    "print(f\"{documents[0][:150]} ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(documents):\n",
    "  \"\"\"\n",
    "  Split the text content of the given list of Document objects into smaller chunks.\n",
    "  Args:\n",
    "    documents: List of documents/chapters containing text content to split.\n",
    "  Returns:\n",
    "    list of chunks: List of Document objects representing the split text chunks.\n",
    "  \"\"\"\n",
    "  # Initialize text splitter with specified parameters\n",
    "  text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=200, # Size of each chunk in characters\n",
    "    chunk_overlap=50, # Overlap between consecutive chunks\n",
    "    length_function=len, # Function to compute the length of the text\n",
    "    add_start_index=True, # Flag to add start index to each chunk\n",
    "    )\n",
    "\n",
    "  # Split documents into smaller chunks using text splitter\n",
    "  chunks = [text_splitter.split_text(doc) for doc in documents]\n",
    "\n",
    "  text = []\n",
    "  title = []\n",
    "  author = []\n",
    "  chapter = []\n",
    "  chunk = []\n",
    "\n",
    "  for i, story in enumerate(chunks):\n",
    "      for j, c in enumerate(story):\n",
    "          text.append(c)\n",
    "          title.append(\"Winnie the Pooh\")\n",
    "          author.append(\"A. A. Milne\")\n",
    "          chapter.append(float(i+1))\n",
    "          chunk.append(float(j))\n",
    "\n",
    "  #metadata = {'title': title, 'author': author, 'chapter': chapter, 'chunk': chunk}\n",
    "  metadata_df = pd.DataFrame({'title': title, 'author': author, 'chapter': chapter, 'chunk': chunk})\n",
    "\n",
    "  return text, metadata_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of text chunks: 796\n",
      "Length of first text chunk: 200\n",
      "Preview of text chunks: \n",
      "  I IN WHICH WE ARE INTRODUCED TO WINNIE-THE-POOH AND SOME BEES, AND THE STORIES BEGIN Here is Edward  ...\n",
      "  back of his head, behind Christopher Robin. It is, as far as he knows, the only way of coming downst ...\n",
      "  another way, if only he could stop bumping for a moment and think of it. And then he feels that perh ...\n",
      "  at the bottom, and ready to be introduced to you. Winnie-the-Pooh. When I first heard his name, I sa ...\n",
      "  was a boy?\" \"So did I,\" said Christopher Robin. \"Then you can't call him Winnie?\" \"I don't.\" \"But yo ...\n"
     ]
    }
   ],
   "source": [
    "text, metadata = split_text(documents)\n",
    "\n",
    "# Inspect text chunks\n",
    "print(f\"Total number of text chunks: {len(text)}\")\n",
    "print(f\"Length of first text chunk: {len(text[0])}\")\n",
    "print(\"Preview of text chunks: \")\n",
    "for chunk in text[:5]:\n",
    "    print(\" \", chunk[:100], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of metadata entries: 796\n",
      "Preview of metadata: \n",
      "             title       author  chapter  chunk\n",
      "0  Winnie the Pooh  A. A. Milne      1.0    0.0\n",
      "1  Winnie the Pooh  A. A. Milne      1.0    1.0\n",
      "2  Winnie the Pooh  A. A. Milne      1.0    2.0\n",
      "3  Winnie the Pooh  A. A. Milne      1.0    3.0\n",
      "4  Winnie the Pooh  A. A. Milne      1.0    4.0 \n",
      "\n",
      "Chapters: [ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.] \n",
      "\n",
      "Chunks: 0 - 109 \n",
      "\n",
      "Chapter 1: 78 chunks\n",
      "Chapter 2: 54 chunks\n",
      "Chapter 3: 46 chunks\n",
      "Chapter 4: 52 chunks\n",
      "Chapter 5: 93 chunks\n",
      "Chapter 6: 96 chunks\n",
      "Chapter 7: 104 chunks\n",
      "Chapter 8: 110 chunks\n",
      "Chapter 9: 94 chunks\n",
      "Chapter 10: 69 chunks\n"
     ]
    }
   ],
   "source": [
    "# Inspect metadata\n",
    "print(f\"Total number of metadata entries: {len(metadata)}\")\n",
    "print(\"Preview of metadata: \")\n",
    "print(metadata.head(), \"\\n\")\n",
    "\n",
    "# Chapters\n",
    "print(f\"Chapters: {metadata['chapter'].unique()} \\n\")\n",
    "\n",
    "# Chunks\n",
    "chunk_min = int(metadata['chunk'].min())\n",
    "chunk_max = int(metadata['chunk'].max())\n",
    "print(f\"Chunks: {chunk_min} - {chunk_max} \\n\")\n",
    "\n",
    "for chapter in metadata['chapter'].unique():\n",
    "    chapter_chunks = metadata[metadata['chapter'] == chapter]\n",
    "    print(f\"Chapter {int(chapter)}: {int(chapter_chunks['chunk'].max())+1} chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Chroma database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_chroma(chunks: list, metadata_df: pd.DataFrame):\n",
    "  \"\"\"\n",
    "  Save the given list of Document objects to a Chroma database.\n",
    "  Args:\n",
    "  chunks (list[Document]): List of Document objects representing text chunks to save.\n",
    "  Returns:\n",
    "  None\n",
    "  \"\"\"\n",
    "  \n",
    "  # Clear out the existing database directory if it exists\n",
    "  if os.path.exists(CHROMA_PATH):\n",
    "    shutil.rmtree(CHROMA_PATH)\n",
    "    \n",
    "\n",
    "  # Create a new Chroma vector database & collection\n",
    "  client = chromadb.PersistentClient(path=CHROMA_PATH)\n",
    "  collection = client.get_or_create_collection(name=\"winnie_the_pooh\", embedding_function=default_ef)\n",
    "  \n",
    "  collection.add(\n",
    "    documents=chunks,\n",
    "    metadatas=[dict(metadata_df.iloc[i]) for i in range(len(metadata_df))], \n",
    "    ids=UUIDGenerator(len(chunks))\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_store():\n",
    "  \"\"\"\n",
    "  Function to generate vector database in chroma from documents.\n",
    "  \"\"\"\n",
    "  documents = load_documents(DATA_PATH) # Load documents from a source\n",
    "  chunks, metadata = split_text(documents) # Split documents into manageable chunks\n",
    "  save_to_chroma(chunks, metadata) # Save the processed data to a data store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "# Generate the data store\n",
    "generate_data_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Querying database\n",
    "\n",
    "Checking the database is populated with expected vectors and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ids', 'distances', 'metadatas', 'embeddings', 'documents', 'uris', 'data', 'included'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = chromadb.PersistentClient(path=CHROMA_PATH)\n",
    "collection = client.get_collection(name=\"winnie_the_pooh\", embedding_function=default_ef)\n",
    "\n",
    "results = collection.query(query_texts='honey', n_results=3)\n",
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Distances: [[1.08407461643219, 1.1015079021453857, 1.1135900020599365]] \n",
      "\n",
      "Chapter: 1.0, Chunk: 17.0\n",
      "then he got up, and said: \"And the only reason for making honey is so as I can eat it.\" So he began to climb the tree. He climbed and he climbed and he climbed, and as he climbed he sang a little  \n",
      "\n",
      "Chapter: 5.0, Chunk: 51.0\n",
      "there. A full jar, full of honey right up to the top, and it had HUNNY written on it, so that I should know it was honey. That's very funny.\" And then he began to wander up and down, wondering where  \n",
      "\n",
      "Chapter: 1.0, Chunk: 16.0\n",
      "know of is because you're a bee.\" Then he thought another long time, and said: \"And the only reason for being a bee that I know of is making honey.\" And then he got up, and said: \"And the only reason  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cosine Similarity Distances: {results['distances']} \\n\")\n",
    "\n",
    "for i in range(len(results['documents'][0])):\n",
    "    print(f\"Chapter: {results['metadatas'][0][i]['chapter']}, Chunk: {results['metadatas'][0][i]['chunk']}\")\n",
    "    print(results['documents'][0][i], \" \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['9cb60098-9d48-4eb7-88d3-ad27219be56f',\n",
       "   'f2181028-69a0-4929-b54f-6d5e3d9e77a4',\n",
       "   '9e0f0231-9f51-4537-946d-8523fb53c7e1']],\n",
       " 'distances': [[1.08407461643219, 1.1015079021453857, 1.1135900020599365]],\n",
       " 'metadatas': [[{'author': 'A. A. Milne',\n",
       "    'chapter': 1.0,\n",
       "    'chunk': 17.0,\n",
       "    'title': 'Winnie the Pooh'},\n",
       "   {'author': 'A. A. Milne',\n",
       "    'chapter': 5.0,\n",
       "    'chunk': 51.0,\n",
       "    'title': 'Winnie the Pooh'},\n",
       "   {'author': 'A. A. Milne',\n",
       "    'chapter': 1.0,\n",
       "    'chunk': 16.0,\n",
       "    'title': 'Winnie the Pooh'}]],\n",
       " 'embeddings': None,\n",
       " 'documents': [['then he got up, and said: \"And the only reason for making honey is so as I can eat it.\" So he began to climb the tree. He climbed and he climbed and he climbed, and as he climbed he sang a little',\n",
       "   'there. A full jar, full of honey right up to the top, and it had HUNNY written on it, so that I should know it was honey. That\\'s very funny.\" And then he began to wander up and down, wondering where',\n",
       "   'know of is because you\\'re a bee.\" Then he thought another long time, and said: \"And the only reason for being a bee that I know of is making honey.\" And then he got up, and said: \"And the only reason']],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'included': ['metadatas', 'documents', 'distances']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
