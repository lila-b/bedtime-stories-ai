{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Story Generator - Winnie the Pooh \n",
    "\n",
    "## Part 3: Integrating Readability Metrics into DSPy Module\n",
    "\n",
    "[1. Imports and environment](#1-imports-and-environment)\n",
    "\n",
    "[2. DSPy set up](#2-dspy-set-up)\n",
    "\n",
    "[3. Evaluation metrics](#3-evaluation-metrics)\n",
    "\n",
    "[4. Gradio UI](#4-gradio-ui)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Imports and environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install dspy-ai openai chromadb sentence_transformers spacy textstat asyncio deepeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['DEEPEVAL_TELEMETRY_OPT_OUT'] = \"YES\"\n",
    "\n",
    "\n",
    "import dspy\n",
    "from dspy.retrieve.chromadb_rm import ChromadbRM\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "import dotenv\n",
    "\n",
    "from deepeval.metrics import AnswerRelevancyMetric\n",
    "from deepeval.test_case import LLMTestCase\n",
    "\n",
    "from evaluation_metrics import *\n",
    "\n",
    "\n",
    "# Establish paths\n",
    "CHROMA_PATH = '../data/chroma_db'\n",
    "DB_COLLECTION = \"winnie_the_pooh\"\n",
    "default_ef = embedding_functions.DefaultEmbeddingFunction()\n",
    "\n",
    "# Set up OpenAI API key\n",
    "dotenv.load_dotenv()\n",
    "#openai_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. DSPy Set up\n",
    "\n",
    "Taken from previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure OpenAI as the language model\n",
    "llm = dspy.OpenAI(model=\"gpt-4o-mini\", max_tokens=1000, temperature=1.0)\n",
    "\n",
    "# Set up Chroma client and retriever\n",
    "chroma_client = chromadb.PersistentClient(path=CHROMA_PATH)\n",
    "collection = chroma_client.get_collection(DB_COLLECTION)\n",
    "\n",
    "# Set up ChromadbRM as the retriever model\n",
    "chroma_retriever = ChromadbRM(\n",
    "    collection_name=DB_COLLECTION, \n",
    "    persist_directory=CHROMA_PATH, \n",
    "    embedding_function=default_ef,\n",
    "    )\n",
    "\n",
    "# Configure DSPy settings\n",
    "dspy.settings.configure(lm=llm, rm=chroma_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GenerateStory(dspy.Signature):\n",
    "    \"\"\"Generate a Winnie the Pooh style story.\"\"\"\n",
    "    name = dspy.InputField()\n",
    "    prompt = dspy.InputField(desc=\"details to include in the story.\")\n",
    "    context = dspy.InputField(desc=\"relevant passages from Winnie the Pooh stories and story structure.\")\n",
    "    story = dspy.OutputField(desc=\"generate a one-minute story for a child. Name is the main character who is friends with Pooh, and finish the story with 'The End.'\")\n",
    "\n",
    "\n",
    "class StoryGenerator(dspy.Module):\n",
    "    def __init__(self, chroma_retriever):\n",
    "        super().__init__()\n",
    "        self.retriever = chroma_retriever\n",
    "        self.generate = dspy.ChainOfThought(GenerateStory)\n",
    "\n",
    "    def forward(self, name, prompt):\n",
    "        retrieved = self.retriever(prompt, k=8)\n",
    "        retrieved_context = [doc.long_text for doc in retrieved]\n",
    "        context = \"\\n\".join(retrieved_context)\n",
    "        \n",
    "        result = self.generate(context=context, prompt=prompt, name=name)\n",
    "        return dspy.Prediction(story=result.story)\n",
    "\n",
    "story_gen = StoryGenerator(chroma_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On a sunny day in the Hundred Acre Wood, Lucy, a cheerful little girl with swirling curls, decided it was the perfect day for a picnic. So she hurried off to find her friend Pooh, who was always up for a tasty treat. \n",
      "\n",
      "“Pooh!” called Lucy, skipping along the path. “Let’s have a picnic by the big oak tree, where the honeybees buzz!”\n",
      "\n",
      "“Oh, that sounds delightful!” replied Pooh, his tummy rumbling in agreement. “I’ll bring some honey, of course!”\n",
      "\n",
      "So, hand in hand, Lucy and Pooh ventured down the winding paths of the wood, singing a happy tune. Along the way, they met Piglet, who was busy picking daisies. \n",
      "\n",
      "“Would you like to join us for a picnic, Piglet?” Lucy asked with a smile.\n",
      "\n",
      "“Oh yes!\" squeaked Piglet, his eyes sparkling. \"I can bring acorn cookies!”\n",
      "\n",
      "As they continued, they bumped into Rabbit, who was hopping near his garden. \n",
      "\n",
      "“Hello, Rabbit!” called Lucy. “We’re having a picnic! Would you like to come?”\n",
      "\n",
      "“Oh, indeed!” said Rabbit, his ears perking up. “I’ll bring some fresh carrots!”\n",
      "\n",
      "Finally, all four friends reached the big oak tree. They spread out a checkered blanket and set their treats on it: honey pots, acorn cookies, and crunchy carrots. \n",
      "\n",
      "Just as they settled down to eat, a gentle breeze fluttered the leaves, and Pooh exclaimed, “Oh dear! I think I smell—”\n",
      "\n",
      "“Honey!” shouted Lucy, giggling at Pooh’s excited expression.\n",
      "\n",
      "As they munched happily, they shared stories and laughed, watching the clouds drift lazily by. The warmth of friendship and the sweetness of the picnic made it a day to remember.\n",
      "\n",
      "And when the sun began to set, painting the sky with orange and pink, Lucy said, “This was the best picnic ever!”\n",
      "\n",
      "With full bellies and happy hearts, they tidied up and promised to have another picnic soon. \n",
      "\n",
      "The End.\n"
     ]
    }
   ],
   "source": [
    "name= 'Lucy'\n",
    "prompt = \"They go into the woods and have a picnic with friends.\"\n",
    "\n",
    "\n",
    "new_story = story_gen(name, prompt)\n",
    "print(new_story.story)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DeepEval - Answer Relevancy\n",
    "\n",
    "Testing one of DeepEval's built-in metrics on a generated story. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e0789abe0e544ee8f291e5a2d6ae383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9354838709677419\n",
      "The score is 0.94 because while the output provided valuable context about the picnic, it included some irrelevant statements that didn't enhance the understanding of the event, such as 'Pooh!' and 'Hello, Rabbit!'. These detracted slightly from the overall relevance, but the main focus on the picnic and friends kept the score high.\n"
     ]
    }
   ],
   "source": [
    "actual_output = new_story.story\n",
    "\n",
    "# Initialize the AnswerRelevancyMetric\n",
    "metric_relecancy = AnswerRelevancyMetric(\n",
    "    threshold=0.7,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    include_reason=True\n",
    ")\n",
    "\n",
    "test_case = LLMTestCase(\n",
    "    input=prompt,\n",
    "    actual_output=actual_output\n",
    ")\n",
    "\n",
    "# Calculate the relevancy score\n",
    "metric_relecancy.measure(test_case)\n",
    "print(metric_relecancy.score)\n",
    "print(metric_relecancy.reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DeepEval's built-in AnswerRelevancyMetric does not seem to be an appropriate metric in this case. Generating a fictional story will inevitably include \"irrelevant\" text from the context. I will instead define a metric that will better assess the appropriateness of the output, by measuring the readability of the generated story. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Readability Score (Flesch-Kincaid Grade)\n",
    "\n",
    "As previously discussed, the Flesch-Kincaid grade level calculation is a readability metric that indicates the reading level of a text, based on word and sentence length. \n",
    "\n",
    "\n",
    "**Flesch–Kincaid grade level** \n",
    "\n",
    "<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/8e68f5fc959d052d1123b85758065afecc4150c3\"\n",
    "     alt=\"Flesch-Kincaid grade formula\"\n",
    "     style=\"margin-left: 45px;\" \n",
    "     />\n",
    "\n",
    "\n",
    "The actual Winnie the Pooh stories have an average readability score 3.8, and standard deviation of 0.8. I would like the generated stories to be no more than one fall within one standard deviation of the mean, and therefore less than 4.6. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Readability acceptable: False\n",
      "Readability score: 4.2\n"
     ]
    }
   ],
   "source": [
    "# Readability metric predefined in and imported from evaluation_metrics.py\n",
    "# defined as a new DeepEval classm with high and low threshholds\n",
    "\n",
    "test_case = LLMTestCase(input=prompt, actual_output=new_story.story)\n",
    "metric = ReadabilityMetric(threshold_high=3.0, threshold_low=2.0)\n",
    "\n",
    "result = metric.measure(test_case)\n",
    "\n",
    "print(\"Readability acceptable:\", result)\n",
    "print(f\"Readability score: {calculate_readability_scores(new_story.story)['Flesch-Kincaid Grade']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, the threshold was set to 2.0-3.0, and the text failed the test becasuse it has a score of 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to evaluate readability of a story\n",
    "\n",
    "def evaluate_readability(name, prompt):\n",
    "    \"\"\"\n",
    "    Generate a story and evaluate its readability.\n",
    "\n",
    "    input: name, prompt\n",
    "    output: readability pass (bool), generated story\n",
    "    \"\"\"\n",
    "\n",
    "    new_story = story_gen(name,prompt)\n",
    "    actual_output = new_story.story\n",
    "\n",
    "    # Initialize the ReadabilityMetric\n",
    "    metric = ReadabilityMetric(\n",
    "        threshold_high=4.6,\n",
    "        #threshold_low=0.0\n",
    "    )\n",
    "\n",
    "    test_case = LLMTestCase(\n",
    "        input= prompt,\n",
    "        actual_output=actual_output\n",
    "    )\n",
    "\n",
    "    return metric.measure(test_case), actual_output\n",
    "\n",
    "\n",
    "# function to adjust prompt/story if it fails readability metric the first time.\n",
    "\n",
    "def print_story(name, prompt):\n",
    "    \"\"\" \n",
    "    print the story if it passes the readability metric, try again with simpler words and sentences if it fails,\n",
    "    otherwise provide a suggestion to simplify the story.\n",
    "\n",
    "    input: name, prompt\n",
    "    output: story or suggestion\n",
    "    \"\"\"\n",
    "    results = evaluate_readability(name, prompt)\n",
    "\n",
    "    pass_metric = results[0]\n",
    "\n",
    "    if pass_metric:\n",
    "        return results[1]\n",
    "\n",
    "    else:\n",
    "        new_prompt = prompt + \" Write the story using simplistic words and sentences.\"\n",
    "\n",
    "        new_results = evaluate_readability(name, new_prompt)\n",
    "\n",
    "        if new_results[0]:\n",
    "            #print(\"Second Try: \\n\", new_results[1]) \n",
    "            return new_results[1]\n",
    "\n",
    "        else:\n",
    "            return \"I'm sorry, I was not able to write you a story. Try a different prompt.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One sunny morning in the Hundred Acre Wood, Noah was feeling quite adventurous. He had woken up with the thought of climbing the tallest tree and seeing the world from up high. As he wandered through the forest, humming a little tune, he bumped into Pooh.\\n\\n“Hello, Noah!” Pooh said, his eyes bright with curiosity. “What are you up to today?”\\n\\n“I’m going to climb that tall tree over there, Pooh! Would you like to come with me?” Noah replied, pointing to a great, leafy tree that stretched towards the sky.\\n\\n“Oh, I do love trees,” said Pooh, “especially the ones that might have honey at the top! Let’s go!”\\n\\nSo off they went together, giggling and chatting. When they reached the foot of the tree, they looked up at the branches that seemed to tickle the clouds.\\n\\n“Do you think we can really climb it?” Noah asked.\\n\\n“Of course! Just think of all the adventures waiting for us up there!” Pooh encouraged, patting Noah's back.\\n\\nTaking a deep breath, Noah began to climb, with Pooh following closely behind. They climbed higher and higher, feeling the excitement in their tummies. Soon, they reached a sturdy branch that jutted out like a cozy little perch.\\n\\n“Look, Pooh! We can see the whole forest from up here!” Noah exclaimed, pointing at the swaying trees and the shimmering streams below.\\n\\n“Oh, it’s lovely!” said Pooh, looking around. “And no sign of honey, but I’m sure it’s just hiding!”\\n\\nAs they settled onto their branch, the two friends giggled at the sight of Tigger bouncing below, giving a cheerful wave. “I see you up there!” Tigger called. “Are you having a frolicking time?”\\n\\n“We are!” Noah shouted back. “And you should come up too!”\\n\\nBut Tigger just laughed and said, “I’ll stick to bouncing! You two enjoy the view!” \\n\\nAfter a delightful time admiring the forest, Noah sighed. “It’s so nice to be up here with you, Pooh.”\\n\\n“It is indeed, Noah,” Pooh agreed. “Sometimes, adventures are better shared with friends.”\\n\\nSo, with one more look at the beautiful forest, Noah and Pooh climbed down, their hearts filled with joy and memories of their grand day.\\n\\nAnd as they walked home together, they felt grateful for their adventure and the wonderful friendship they cherished.\\n\\nThe End.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_name = 'Noah'\n",
    "test_prompt = \"They go on an adventure and climb a tree.\"\n",
    "\n",
    "print_story(test_name, test_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Gradio UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from theme_violet_amber import theme as violet_amber\n",
    "\n",
    "\n",
    "# Gradio UI\n",
    "with gr.Blocks(theme=violet_amber) as demo:\n",
    "    gr.Markdown(\n",
    "    \"\"\"\n",
    "    # Winnie the Pooh Story Generator\n",
    "    *Simply enter a character name and setting, then I will write a story from the Hundred Acre Woods for you!*\n",
    "    \"\"\")\n",
    "    textbox = gr.Textbox(label=\"Who is the story about?\")\n",
    "    textbox2 = gr.Textbox(label=\"What do you want the story to be about?\")\n",
    "\n",
    "    with gr.Row():\n",
    "        button = gr.Button(\"Submit\", variant=\"primary\")\n",
    "        clear = gr.ClearButton([textbox, textbox2]) \n",
    "\n",
    "    output = gr.Textbox(label=\"A story for you... \")\n",
    "\n",
    "    button.click(print_story, [textbox, textbox2], output)\n",
    "    clear.click(lambda: None, outputs = output)\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "demo.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
